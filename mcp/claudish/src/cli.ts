import { ENV } from "./config.js";
import type { ClaudishConfig } from "./types.js";
import { loadModelInfo, getAvailableModels } from "./model-loader.js";
import { readFileSync, writeFileSync, existsSync } from "node:fs";
import { fileURLToPath } from "node:url";
import { dirname, join } from "node:path";

// Read version from package.json
const __filename = fileURLToPath(import.meta.url);
const __dirname = dirname(__filename);
const packageJson = JSON.parse(
  readFileSync(join(__dirname, "../package.json"), "utf-8")
);
const VERSION = packageJson.version;

/**
 * Parse CLI arguments and environment variables
 */
export async function parseArgs(args: string[]): Promise<ClaudishConfig> {
  const config: Partial<ClaudishConfig> = {
    model: undefined, // Will prompt interactively if not provided
    autoApprove: true, // Skip permissions by default (--dangerously-skip-permissions)
    dangerous: false,
    interactive: false, // Single-shot mode by default
    debug: false, // No debug logging by default
    logLevel: "info", // Default to info level (structured logging with truncated content)
    quiet: undefined, // Will be set based on mode (true for single-shot, false for interactive)
    jsonOutput: false, // No JSON output by default
    monitor: false, // Monitor mode disabled by default
    stdin: false, // Read prompt from stdin instead of args
    claudeArgs: [],
  };

  // Check for environment variable overrides
  // Priority order: CLAUDISH_MODEL (Claudish-specific) > ANTHROPIC_MODEL (Claude Code standard)
  // CLI --model flag will override both (handled later in arg parsing)
  const claudishModel = process.env[ENV.CLAUDISH_MODEL];
  const anthropicModel = process.env[ENV.ANTHROPIC_MODEL];

  if (claudishModel) {
    config.model = claudishModel; // Claudish-specific takes priority
  } else if (anthropicModel) {
    config.model = anthropicModel; // Fall back to Claude Code standard
  }

  const envPort = process.env[ENV.CLAUDISH_PORT];
  if (envPort) {
    const port = Number.parseInt(envPort, 10);
    if (!Number.isNaN(port)) {
      config.port = port;
    }
  }

  // Parse command line arguments
  let i = 0;
  while (i < args.length) {
    const arg = args[i];

    if (arg === "--model" || arg === "-m") {
      const modelArg = args[++i];
      if (!modelArg) {
        console.error("--model requires a value");
        printAvailableModels();
        process.exit(1);
      }
      config.model = modelArg; // Accept any model ID
    } else if (arg === "--port" || arg === "-p") {
      const portArg = args[++i];
      if (!portArg) {
        console.error("--port requires a value");
        process.exit(1);
      }
      const port = Number.parseInt(portArg, 10);
      if (Number.isNaN(port) || port < 1 || port > 65535) {
        console.error(`Invalid port: ${portArg}`);
        process.exit(1);
      }
      config.port = port;
    } else if (arg === "--no-auto-approve") {
      config.autoApprove = false;
    } else if (arg === "--dangerous") {
      config.dangerous = true;
    } else if (arg === "--interactive" || arg === "-i") {
      config.interactive = true;
    } else if (arg === "--debug" || arg === "-d") {
      config.debug = true;
    } else if (arg === "--log-level") {
      const levelArg = args[++i];
      if (!levelArg || !["debug", "info", "minimal"].includes(levelArg)) {
        console.error("--log-level requires one of: debug, info, minimal");
        process.exit(1);
      }
      config.logLevel = levelArg as "debug" | "info" | "minimal";
    } else if (arg === "--quiet" || arg === "-q") {
      config.quiet = true;
    } else if (arg === "--verbose" || arg === "-v") {
      config.quiet = false;
    } else if (arg === "--json") {
      config.jsonOutput = true;
    } else if (arg === "--monitor") {
      config.monitor = true;
    } else if (arg === "--stdin") {
      config.stdin = true;
    } else if (arg === "--cost-tracker") {
      // Enable cost tracking for this session
      config.costTracking = true;
      // In monitor mode, we'll track costs instead of proxying
      if (!config.monitor) {
        config.monitor = true; // Switch to monitor mode to track requests
      }
    } else if (arg === "--audit-costs") {
      // Special mode to just show cost analysis
      config.auditCosts = true;
    } else if (arg === "--reset-costs") {
      // Reset accumulated cost statistics
      config.resetCosts = true;
    } else if (arg === "--version") {
      printVersion();
      process.exit(0);
    } else if (arg === "--help" || arg === "-h") {
      printHelp();
      process.exit(0);
    } else if (arg === "--help-ai") {
      printAIAgentGuide();
      process.exit(0);
    } else if (arg === "--list-models") {
      // Check for --json and --force-update flags
      const hasJsonFlag = args.includes("--json");
      const forceUpdate = args.includes("--force-update");

      // Auto-update if cache is stale (>2 days) or if --force-update is specified
      await checkAndUpdateModelsCache(forceUpdate);

      if (hasJsonFlag) {
        printAvailableModelsJSON();
      } else {
        printAvailableModels();
      }
      process.exit(0);
    } else {
      // All remaining args go to claude CLI
      config.claudeArgs = args.slice(i);
      break;
    }

    i++;
  }

  // Determine if this will be interactive mode BEFORE API key check
  // If no prompt provided and not explicitly interactive, default to interactive mode
  // Exception: --stdin mode reads prompt from stdin, so don't default to interactive
  if ((!config.claudeArgs || config.claudeArgs.length === 0) && !config.stdin) {
    config.interactive = true;
  }

  // Handle API keys based on mode
  if (config.monitor) {
    // Monitor mode: extracts API key from Claude Code's requests
    // No need for user to provide API key - we intercept it from Claude Code
    // IMPORTANT: Unset ANTHROPIC_API_KEY if it's a placeholder, so Claude Code uses its native auth
    if (process.env.ANTHROPIC_API_KEY && process.env.ANTHROPIC_API_KEY.includes('placeholder')) {
      delete process.env.ANTHROPIC_API_KEY;
      if (!config.quiet) {
        console.log("[claudish] Removed placeholder API key - Claude Code will use native authentication");
      }
    }

    if (!config.quiet) {
      console.log("[claudish] Monitor mode enabled - proxying to real Anthropic API");
      console.log("[claudish] API key will be extracted from Claude Code's requests");
      console.log("[claudish] Ensure you are logged in to Claude Code (claude auth login)");
    }
  } else {
    // OpenRouter mode: requires OpenRouter API key
    const apiKey = process.env[ENV.OPENROUTER_API_KEY];
    if (!apiKey) {
      // In interactive mode, we'll prompt for it later
      // In non-interactive mode, it's required now
      if (!config.interactive) {
        console.error("Error: OPENROUTER_API_KEY environment variable is required");
        console.error("Get your API key from: https://openrouter.ai/keys");
        console.error("");
        console.error("Set it now:");
        console.error("  export OPENROUTER_API_KEY='sk-or-v1-...'");
        process.exit(1);
      }
      // Will be prompted for in interactive mode
      config.openrouterApiKey = undefined;
    } else {
      config.openrouterApiKey = apiKey;
    }

    // Note: ANTHROPIC_API_KEY is NOT required here
    // claude-runner.ts automatically sets a placeholder if not provided (see line 138)
    // This allows single-variable setup - users only need OPENROUTER_API_KEY
    config.anthropicApiKey = process.env.ANTHROPIC_API_KEY;
  }

  // Set default for quiet mode if not explicitly set
  // Single-shot mode: quiet by default
  // Interactive mode: verbose by default
  // JSON output: always quiet
  if (config.quiet === undefined) {
    config.quiet = !config.interactive;
  }
  if (config.jsonOutput) {
    config.quiet = true; // JSON output mode is always quiet
  }

  return config as ClaudishConfig;
}

/**
 * Cache Management Constants
 */
const CACHE_MAX_AGE_DAYS = 2;
const MODELS_JSON_PATH = join(__dirname, "../recommended-models.json");

/**
 * Check if models cache is stale (older than CACHE_MAX_AGE_DAYS)
 */
function isCacheStale(): boolean {
  if (!existsSync(MODELS_JSON_PATH)) {
    return true; // No cache file = stale
  }

  try {
    const jsonContent = readFileSync(MODELS_JSON_PATH, "utf-8");
    const data = JSON.parse(jsonContent);

    if (!data.lastUpdated) {
      return true; // No timestamp = stale
    }

    const lastUpdated = new Date(data.lastUpdated);
    const now = new Date();
    const ageInDays = (now.getTime() - lastUpdated.getTime()) / (1000 * 60 * 60 * 24);

    return ageInDays > CACHE_MAX_AGE_DAYS;
  } catch (error) {
    // If we can't read/parse, consider it stale
    return true;
  }
}

/**
 * Fetch models from OpenRouter and update recommended-models.json
 *
 * IMPORTANT: This function matches the exact models shown on OpenRouter's programming page:
 * https://openrouter.ai/models?categories=programming&fmt=cards&order=top-weekly
 *
 * **Why hardcoded list?**
 * The OpenRouter website uses client-side rendering (React/Next.js), making it impossible
 * to scrape the HTML with simple HTTP requests. The API doesn't expose the "top-weekly"
 * ranking either. Therefore, we maintain a manually curated list based on the website.
 *
 * **Filtering rules:**
 * 1. Match the top 10 models from the "Top Weekly" programming category (verified manually)
 * 2. Take only ONE model per provider (the top-ranked one)
 *
 * **Maintenance:** Update this list when the OpenRouter website rankings change.
 * Last verified: 2025-11-19
 */
async function updateModelsFromOpenRouter(): Promise<void> {
  console.error("üîÑ Updating model recommendations from OpenRouter...");

  try {
    // Top Weekly Programming Models (manually verified from the website)
    // Source: https://openrouter.ai/models?categories=programming&fmt=cards&order=top-weekly
    // Last verified: 2025-11-19
    //
    // This list represents the EXACT ranking shown on OpenRouter's website.
    // The website is client-side rendered (React), so we can't scrape it with HTTP.
    // The API doesn't expose the "top-weekly" ranking, so we maintain this manually.
    const topWeeklyProgrammingModels = [
      "x-ai/grok-code-fast-1",            // #1: xAI Grok Code Fast 1
      "anthropic/claude-sonnet-4.5",      // #2: Anthropic Claude Sonnet 4.5
      "google/gemini-2.5-flash",          // #3: Google Gemini 2.5 Flash
      "minimax/minimax-m2",               // #4: MiniMax M2
      "anthropic/claude-sonnet-4",        // #5: Anthropic Claude Sonnet 4
      "z-ai/glm-4.6",                     // #6: Z.AI GLM 4.6
      "anthropic/claude-haiku-4.5",       // #7: Anthropic Claude Haiku 4.5
      "openai/gpt-5",                     // #8: OpenAI GPT-5
      "qwen/qwen3-vl-235b-a22b-instruct", // #9: Qwen3 VL 235B
      "openrouter/polaris-alpha",         // #10: Polaris Alpha (OpenRouter experimental)
    ];

    // Fetch model metadata from OpenRouter API
    const apiResponse = await fetch("https://openrouter.ai/api/v1/models");
    if (!apiResponse.ok) {
      throw new Error(`OpenRouter API returned ${apiResponse.status}`);
    }

    const openrouterData = await apiResponse.json();
    const allModels = openrouterData.data;

    // Build a map for quick lookup
    const modelMap = new Map();
    for (const model of allModels) {
      modelMap.set(model.id, model);
    }

    // Build recommendations list following the exact website ranking
    const recommendations: any[] = [];
    const providers = new Set<string>();

    for (const modelId of topWeeklyProgrammingModels) {
      const provider = modelId.split("/")[0];

      // Filter 1: Skip Anthropic models (not needed in Claudish)
      if (provider === "anthropic") {
        continue;
      }

      // Filter 2: Only ONE model per provider (take the first/top-ranked)
      if (providers.has(provider)) {
        continue;
      }

      const model = modelMap.get(modelId);
      if (!model) {
        // Model not in API yet (e.g., upcoming model like polaris-alpha)
        // Still include it in the list with minimal metadata
        console.error(`‚ö†Ô∏è  Model ${modelId} not found in OpenRouter API (including with limited metadata)`);

        recommendations.push({
          id: modelId,
          name: modelId.split("/")[1].replace(/-/g, " ").replace(/\b\w/g, l => l.toUpperCase()),
          description: `${modelId} (metadata pending - not yet available in API)`,
          provider: provider.charAt(0).toUpperCase() + provider.slice(1),
          category: "programming",
          priority: recommendations.length + 1,
          pricing: {
            input: "N/A",
            output: "N/A",
            average: "N/A"
          },
          context: "N/A",
          maxOutputTokens: null,
          modality: "text->text",
          supportsTools: false,
          supportsReasoning: false,
          supportsVision: false,
          isModerated: false,
          recommended: true
        });

        providers.add(provider);
        continue;
      }

      const name = model.name || modelId;
      const description = model.description || `${name} model`;
      const architecture = model.architecture || {};
      const topProvider = model.top_provider || {};
      const supportedParams = model.supported_parameters || [];

      // Calculate pricing (handle both per-token and per-million formats)
      const promptPrice = parseFloat(model.pricing?.prompt || "0");
      const completionPrice = parseFloat(model.pricing?.completion || "0");

      const inputPrice = promptPrice > 0
        ? `$${(promptPrice * 1000000).toFixed(2)}/1M`
        : "FREE";
      const outputPrice = completionPrice > 0
        ? `$${(completionPrice * 1000000).toFixed(2)}/1M`
        : "FREE";
      const avgPrice = (promptPrice > 0 || completionPrice > 0)
        ? `$${((promptPrice + completionPrice) / 2 * 1000000).toFixed(2)}/1M`
        : "FREE";

      // Determine category based on description and capabilities
      let category = "programming"; // default since we're filtering programming models
      const lowerDesc = description.toLowerCase() + " " + name.toLowerCase();

      if (lowerDesc.includes("vision") || lowerDesc.includes("vl-") || lowerDesc.includes("multimodal")) {
        category = "vision";
      } else if (lowerDesc.includes("reason")) {
        category = "reasoning";
      }

      recommendations.push({
        id: modelId,
        name,
        description,
        provider: provider.charAt(0).toUpperCase() + provider.slice(1),
        category,
        priority: recommendations.length + 1,
        pricing: {
          input: inputPrice,
          output: outputPrice,
          average: avgPrice
        },
        context: topProvider.context_length
          ? `${Math.floor(topProvider.context_length / 1000)}K`
          : "N/A",
        maxOutputTokens: topProvider.max_completion_tokens || null,
        modality: architecture.modality || "text->text",
        supportsTools: supportedParams.includes("tools") || supportedParams.includes("tool_choice"),
        supportsReasoning: supportedParams.includes("reasoning") || supportedParams.includes("include_reasoning"),
        supportsVision: (architecture.input_modalities || []).includes("image") ||
                       (architecture.input_modalities || []).includes("video"),
        isModerated: topProvider.is_moderated || false,
        recommended: true
      });

      providers.add(provider);
    }

    // Read existing version if available
    let version = "1.1.5"; // default
    if (existsSync(MODELS_JSON_PATH)) {
      try {
        const existing = JSON.parse(readFileSync(MODELS_JSON_PATH, "utf-8"));
        version = existing.version || version;
      } catch {
        // Use default version
      }
    }

    // Create new JSON structure
    const updatedData = {
      version,
      lastUpdated: new Date().toISOString().split('T')[0], // YYYY-MM-DD format
      source: "https://openrouter.ai/models?categories=programming&fmt=cards&order=top-weekly",
      models: recommendations
    };

    // Write to file
    writeFileSync(MODELS_JSON_PATH, JSON.stringify(updatedData, null, 2), "utf-8");

    console.error(`‚úÖ Updated ${recommendations.length} models (last updated: ${updatedData.lastUpdated})`);
  } catch (error) {
    console.error(`‚ùå Failed to update models: ${error instanceof Error ? error.message : String(error)}`);
    console.error("   Using cached models (if available)");
  }
}

/**
 * Check cache staleness and update if needed
 */
async function checkAndUpdateModelsCache(forceUpdate: boolean = false): Promise<void> {
  if (forceUpdate) {
    console.error("üîÑ Force update requested...");
    await updateModelsFromOpenRouter();
    return;
  }

  if (isCacheStale()) {
    console.error("‚ö†Ô∏è  Model cache is stale (>2 days old), updating...");
    await updateModelsFromOpenRouter();
  } else {
    // Cache is fresh, show timestamp in stderr (won't affect JSON output)
    try {
      const data = JSON.parse(readFileSync(MODELS_JSON_PATH, "utf-8"));
      console.error(`‚úì Using cached models (last updated: ${data.lastUpdated})`);
    } catch {
      // Silently fallthrough if can't read
    }
  }
}

/**
 * Print version information
 */
function printVersion(): void {
  console.log(`claudish version ${VERSION}`);
}

/**
 * Print help message
 */
function printHelp(): void {
  console.log(`
claudish - Run Claude Code with OpenRouter models

USAGE:
  claudish                                # Interactive mode (default, shows model selector)
  claudish [OPTIONS] <claude-args...>     # Single-shot mode (requires --model)

OPTIONS:
  -i, --interactive        Run in interactive mode (default when no prompt given)
  -m, --model <model>      OpenRouter model to use (required for single-shot mode)
  -p, --port <port>        Proxy server port (default: random)
  -d, --debug              Enable debug logging to file (logs/claudish_*.log)
  --log-level <level>      Log verbosity: debug (full), info (truncated), minimal (labels only)
  -q, --quiet              Suppress [claudish] log messages (default in single-shot mode)
  -v, --verbose            Show [claudish] log messages (default in interactive mode)
  --json                   Output in JSON format for tool integration (implies --quiet)
  --stdin                  Read prompt from stdin (useful for large prompts or piping)
  --monitor                Monitor mode - proxy to REAL Anthropic API and log all traffic
  --no-auto-approve        Disable auto permission skip (prompts enabled)
  --dangerous              Pass --dangerouslyDisableSandbox to Claude Code
  --cost-tracker           Enable cost tracking for API usage (NB!)
  --audit-costs            Show cost analysis report
  --reset-costs            Reset accumulated cost statistics
  --list-models            List available OpenRouter models (auto-updates if stale >2 days)
  --list-models --json     Output model list in JSON format
  --force-update           Force refresh model cache from OpenRouter API
  --version                Show version information
  -h, --help               Show this help message
  --help-ai                Show AI agent usage guide (file-based patterns, sub-agents)

MODES:
  ‚Ä¢ Interactive mode (default): Shows model selector, starts persistent session
  ‚Ä¢ Single-shot mode: Runs one task in headless mode and exits (requires --model)

NOTES:
  ‚Ä¢ Permission prompts are SKIPPED by default (--dangerously-skip-permissions)
  ‚Ä¢ Use --no-auto-approve to enable permission prompts
  ‚Ä¢ Model selector appears ONLY in interactive mode when --model not specified
  ‚Ä¢ Use --dangerous to disable sandbox (use with extreme caution!)

ENVIRONMENT VARIABLES:
  OPENROUTER_API_KEY              Required: Your OpenRouter API key
  CLAUDISH_MODEL                  Default model to use (takes priority)
  ANTHROPIC_MODEL                 Claude Code standard: model to use (fallback if CLAUDISH_MODEL not set)
  ANTHROPIC_SMALL_FAST_MODEL      Claude Code standard: fast model (auto-set by claudish)
  CLAUDISH_PORT                   Default port for proxy
  CLAUDISH_ACTIVE_MODEL_NAME      Auto-set by claudish (read-only) - shows active model in status line

EXAMPLES:
  # Interactive mode (default) - shows model selector
  claudish
  claudish --interactive

  # Interactive mode with pre-selected model
  claudish --model x-ai/grok-code-fast-1

  # Single-shot mode - one task and exit (requires --model or CLAUDISH_MODEL env var)
  claudish --model openai/gpt-5-codex "implement user authentication"
  claudish --model x-ai/grok-code-fast-1 "add tests for login"

  # Use stdin for large prompts (e.g., git diffs, code review)
  echo "Review this code..." | claudish --stdin --model x-ai/grok-code-fast-1
  git diff | claudish --stdin --model openai/gpt-5-codex "Review these changes"

  # Monitor mode - understand how Claude Code works (requires real Anthropic API key)
  claudish --monitor --debug "analyze code structure"

  # Disable auto-approve (require manual confirmation)
  claudish --no-auto-approve "make changes to config"

  # Dangerous mode (disable sandbox - use with extreme caution)
  claudish --dangerous "refactor entire codebase"

  # Both flags (fully autonomous)
  claudish --dangerous "refactor entire codebase"

  # With custom port
  claudish --port 3000 "analyze code structure"

  # Pass flags to claude
  claudish --model x-ai/grok-code-fast-1 --verbose "debug issue"

  # JSON output for tool integration (quiet by default)
  claudish --json "list 5 prime numbers"

  # Verbose mode in single-shot (show [claudish] logs)
  claudish --verbose "analyze code structure"

AVAILABLE MODELS:
  List models: claudish --list-models
  JSON output: claudish --list-models --json
  Force update: claudish --list-models --force-update
  (Cache auto-updates every 2 days)

MORE INFO:
  GitHub: https://github.com/MadAppGang/claude-code
  OpenRouter: https://openrouter.ai
`);
}

/**
 * Print AI agent usage guide
 */
function printAIAgentGuide(): void {
  try {
    const guidePath = join(__dirname, "../AI_AGENT_GUIDE.md");
    const guideContent = readFileSync(guidePath, "utf-8");
    console.log(guideContent);
  } catch (error) {
    console.error("Error reading AI Agent Guide:");
    console.error(error instanceof Error ? error.message : String(error));
    console.error("\nThe guide should be located at: AI_AGENT_GUIDE.md");
    console.error("You can also view it online at:");
    console.error("https://github.com/MadAppGang/claude-code/blob/main/mcp/claudish/AI_AGENT_GUIDE.md");
    process.exit(1);
  }
}

/**
 * Print available models in enhanced table format
 */
function printAvailableModels(): void {
  // Try to read enhanced model data from JSON file
  let lastUpdated = "unknown";
  let models: any[] = [];

  try {
    if (existsSync(MODELS_JSON_PATH)) {
      const data = JSON.parse(readFileSync(MODELS_JSON_PATH, "utf-8"));
      lastUpdated = data.lastUpdated || "unknown";
      models = data.models || [];
    }
  } catch {
    // Fallback to basic model list
    const basicModels = getAvailableModels();
    const modelInfo = loadModelInfo();
    for (const model of basicModels) {
      const info = modelInfo[model];
      console.log(`  ${model}`);
      console.log(`    ${info.name} - ${info.description}`);
      console.log("");
    }
    return;
  }

  console.log(`\nAvailable OpenRouter Models (last updated: ${lastUpdated}):\n`);

  // Table header
  console.log("  Model                          Provider    Pricing     Context  Capabilities");
  console.log("  " + "‚îÄ".repeat(86));

  // Table rows
  for (const model of models) {
    // Format model ID (truncate if too long)
    const modelId = model.id.length > 30 ? model.id.substring(0, 27) + "..." : model.id;
    const modelIdPadded = modelId.padEnd(30);

    // Format provider (max 10 chars)
    const provider = model.provider.length > 10 ? model.provider.substring(0, 7) + "..." : model.provider;
    const providerPadded = provider.padEnd(10);

    // Format pricing (average) - handle special cases
    let pricing = model.pricing?.average || "N/A";

    // Handle special pricing cases
    if (pricing.includes("-1000000")) {
      pricing = "varies"; // Auto-router pricing varies by routed model
    } else if (pricing === "$0.00/1M" || pricing === "FREE") {
      pricing = "FREE";
    }

    const pricingPadded = pricing.padEnd(10);

    // Format context
    const context = model.context || "N/A";
    const contextPadded = context.padEnd(7);

    // Capabilities emojis
    const tools = model.supportsTools ? "üîß" : "  ";
    const reasoning = model.supportsReasoning ? "üß†" : "  ";
    const vision = model.supportsVision ? "üëÅÔ∏è " : "  ";
    const capabilities = `${tools} ${reasoning} ${vision}`;

    console.log(`  ${modelIdPadded} ${providerPadded} ${pricingPadded} ${contextPadded} ${capabilities}`);
  }

  console.log("");
  console.log("  Capabilities: üîß Tools  üß† Reasoning  üëÅÔ∏è  Vision");
  console.log("");
  console.log("Set default with: export CLAUDISH_MODEL=<model>");
  console.log("               or: export ANTHROPIC_MODEL=<model>");
  console.log("Or use: claudish --model <model> ...");
  console.log("\nForce update: claudish --list-models --force-update\n");
}

/**
 * Print available models in JSON format
 */
function printAvailableModelsJSON(): void {
  const jsonPath = join(__dirname, "../recommended-models.json");

  try {
    const jsonContent = readFileSync(jsonPath, "utf-8");
    const data = JSON.parse(jsonContent);

    // Output clean JSON to stdout
    console.log(JSON.stringify(data, null, 2));
  } catch (error) {
    // If JSON file doesn't exist, construct from model info
    const models = getAvailableModels();
    const modelInfo = loadModelInfo();

    const output = {
      version: VERSION,
      lastUpdated: new Date().toISOString().split('T')[0],
      source: "runtime",
      models: models
        .filter(m => m !== 'custom')
        .map(modelId => {
          const info = modelInfo[modelId];
          return {
            id: modelId,
            name: info.name,
            description: info.description,
            provider: info.provider,
            priority: info.priority
          };
        })
    };

    console.log(JSON.stringify(output, null, 2));
  }
}
